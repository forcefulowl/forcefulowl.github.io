---
layout: post
title:  Keras-python
subtitle:   Deep learning/持续更新
date:   2018-01-22
author: gavin
header-img: img/post-bg-deeplearning.png
catalog:    true
tags:
    - deep learning
---

>记录一下keras-python学习过程

# KNN

### description

KNN是一种用于分类和回归的非参数统计(nonparametric)方法，非参数统计即不对样本分布做假设，直接分析样本的一类统计方法。
简单来说, KNN指训练完train set后，当给出test时，根据离test距离最近的k个train的值，确定test的值。
这里距离test的距离分为两种：L1 distance/ L2 distance。L1 distance也叫manhattan distance，计算的是两点在坐标系上的截距总和，因此L1 distance依赖coordinate system; L2 distance也叫Euclidean distance，计算的是两点的直线距离，不依赖coordinate system。

在KNN中，K被称为hyper-parameter，需要我们在训练的时候调整来达到better performance。目前比较好的方法是把数据分为train, validation, test。训练train set, 用validation set evaluate， 找到best performance的k去跑test。

KNN不适合用于vision recognition。

附上KNN demo: [KNN](http://vision.stanford.edu/teaching/cs231n-demos/knn/)

### Implementation(iris)

```python

from sklearn.datasets import load_iris  
from sklearn import neighbors  
import sklearn
iris = load_iris()
knn = neighbors.KNeighborsClassifier().fit(iris.data, iris.target)
predict = knn.predict([[0.1,0.2,0.3,0.4]])
print(predict)
print iris.target_names[predict]

```

About `sklearn.neighbor.KNeighborsClassifier()`
```python
###other example
X = [[0], [1], [2], [3]]
y = [0, 0, 1, 1]
from sklearn.neighbors import KNeighborsClassifier
neigh = KNeighborsClassifier(n_neighbors=3).fit(X,y)
print(neigh.predict([[1.1]]))

```
Some methods:

Name | description
---- | -----------
fit(X,y) | Fit the model using X as training data and y as target values
predict(X) | Predict the class labels for the provided data
predict_proba(X) | Return probability estimates for the test data X.

more details:[sklearn.neighbors.KNeighborsClassifier()](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)

# Sequential Model/序贯模型

简历一个简单的Sequential model

```python
from keras.models import Sequential

model = Sequential()
```

接下来为该模型建立layers

```python
from keras.layers import Dense, Dropout
model.add(Dense(64, input_dim = 20, activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation = 'sigmoid'))

```
然后compile我们的模型
```python
model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])
```

Generate dummy data

```python
x_train = np.random.random((1000, 20))
y_train = np.random.randint(2, size=(1000, 1))
x_test = np.random.random((100, 20))
y_test = np.random.randint(2, size=(100, 1))

```

训练开始

```python
model.fit(x_train, y_train,batch_size = 200,epochs = 10)
```

## 补充

### tensor 张量

```python
>>> import numpy as np
>>> import math
>>> a = np.array([[1,2,3],[4,5,6]])
>>> print(a)
[[1 2 3]
 [4 5 6]]
>>> a.shape()
(2, 3)
>>> b = np.array([1,2,3])
>>> print(b)
[1 2 3]
>>> np.shape(b)
(3,)

```
与矩阵中概念不同，shape(2,3)指第一维有2个元素，第二维有3个元素

### Definitions of parameters

Dense即为全连接层，意为层与层之间所有节点都互相相连。

keras.layers.Dense(units, input_dim, activation)

`units` output space

`input_dim` 对输入数据的维度要求，只在第一层做要求。

keras.layers.Dropout(rate)

`rate` 每次batch忽略结点的rate

`batch_size` 一次iteration需要跑的sample数量。

`epochs` 跑完一次全部数据

综上， epoch = nums of iterations = nusm of samples/batch_size




